# ğŸ§  Offline Mistral Chatbot

An offline, privacy-respecting chatbot powered by the Mistral 7B Instruct model in GGUF format. Runs locally using llama-cpp-python, with both command-line and graphical interfaces for interaction. No internet connection required after setup.

---

## ğŸš€ Features

- âœ… Offline LLM Chatting
- ğŸ§  Mistral 7B Instruct (Quantized GGUF)
- ğŸ’¬ Command Line & GUI (Tkinter) modes
- ğŸ–¥ï¸ Cross-platform: Windows, Linux, macOS
- ğŸ”’ Private & Secure â€“ no data sent to cloud

---

## ğŸ“ Project Structure

offline-chatbot/
â”œâ”€â”€ chatbot.py # Command-line chatbot
â”œâ”€â”€ gui.py # GUI using Tkinter
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ mistral-7b-instruct-v0.1.Q4_0.gguf # Mistral model file
â””â”€â”€ README.md # This documentation

---

## ğŸ“¥ Download the Model

You must manually download the quantized Mistral 7B model in GGUF format.

ğŸ”— Hosted on Hugging Face:  
https://huggingface.co/MUPPALAM/mistral

â¬‡ï¸ Direct model link (4.1 GB):  
https://huggingface.co/MUPPALAM/mistral/resolve/main/mistral-7b-instruct-v0.1.Q4_0.gguf

ğŸ—‚ï¸ Place the file in the project folder:


---

---

## ğŸ’» Setup

1. Clone the repository:

```bash
git clone https://github.com/prem90902304/offline-chatbot.git
cd offline-chatbot

